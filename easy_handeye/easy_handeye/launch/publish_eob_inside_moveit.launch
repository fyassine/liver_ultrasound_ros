<?xml version="1.0"?>
<launch>

  <!-- =========================================================
       Publish setup for Eye-on-Base (EOB)
       - camera is fixed in the world/robot-base environment
       - marker is mounted on the robot end-effector
       - publishes the calibrated transform using easy_handeye/publish.launch
       ========================================================= -->

  <!-- Calibration settings -->
  <arg name="marker_id" default="582"/>
  <arg name="marker_size" default="0.083"/>
  <arg name="corner_refinement" default="LINES"/>
  <arg name="namespace_prefix" default="my_eob_calib"/>

  <!-- Robot configuration -->
  <arg name="robot_name" default="iiwa"/>
  <arg name="model" default="iiwa7"/>
  <arg name="hardware_interface" default="PositionJointInterface"/>
  <arg name="robot_base_frame" default="iiwa_link_0"/>
  <arg name="robot_effector_frame" default="iiwa_link_ee"/>

  <!-- Camera configuration -->
  <arg name="tracking_base_frame" default="camera_base"/>
  <arg name="camera_frame" default="rgb_camera_link"/>
  <arg name="marker_frame" default="aruco_marker_frame"/>
  <arg name="camera_image_topic" default="/rgb/image_raw"/>
  <arg name="camera_info_topic" default="/rgb/camera_info"/>

  <!-- Azure Kinect settings -->
  <arg name="depth_mode" value="NFOV_2X2BINNED"/>
  <arg name="color_resolution" value="720P"/>
  <arg name="fps" value="5"/>
  <arg name="rgb_point_cloud" value="false"/>
  <arg name="point_cloud" value="false"/>

  <!-- Visualization -->
  <arg name="world_frame" default="world"/>
  <arg name="publish_world_tf" default="true"/>
  <arg name="world_to_robot_xyz" default="0 0 0"/>
  <arg name="world_to_robot_rpy" default="0 0 0"/>

  <!-- Optional: provide a known static mount between robot base and camera base
       ONLY enable if you know this transform.
       This is useful so RViz has a coherent TF tree: world -> robot_base -> camera_base
  -->
  <arg name="publish_camera_mount_tf" default="false"/>
  <arg name="robot_base_to_camera_xyz" default="0 0 0"/>
  <arg name="robot_base_to_camera_rpy" default="0 0 0"/>

  <!-- Start robot + MoveIt with RViz -->
  <include file="$(find iiwa_moveit)/launch/moveit_planning_execution.launch">
    <arg name="sim" value="false"/>
    <arg name="rviz" value="true"/>
    <arg name="hardware_interface" value="$(arg hardware_interface)"/>
    <arg name="robot_name" value="$(arg robot_name)"/>
    <arg name="model" value="$(arg model)"/>
  </include>

  <!-- World frame publisher -->
  <group if="$(arg publish_world_tf)">
    <node name="world_to_$(arg robot_base_frame)" pkg="tf" type="static_transform_publisher"
          args="$(arg world_to_robot_xyz) $(arg world_to_robot_rpy) $(arg world_frame) $(arg robot_base_frame) 30"/>
  </group>

  <!-- Optional static mount: robot base -> camera base -->
  <group if="$(arg publish_camera_mount_tf)">
    <node name="robot_base_to_camera_base" pkg="tf" type="static_transform_publisher"
          args="$(arg robot_base_to_camera_xyz) $(arg robot_base_to_camera_rpy) $(arg robot_base_frame) $(arg tracking_base_frame) 30"/>
  </group>

  <!-- Relay joint states from /iiwa/joint_states to /joint_states for visualization -->
  <node name="joint_state_relay" pkg="topic_tools" type="relay"
        args="/iiwa/joint_states /joint_states" respawn="true"/>

  <!-- Publish hand-eye calibration transform (EOB) -->
  <include file="$(find easy_handeye)/launch/publish.launch">
    <arg name="namespace_prefix" value="$(arg namespace_prefix)"/>
    <arg name="eye_on_hand" value="false"/>
  </include>

  <!-- Azure Kinect camera -->
  <include file="$(find azure_kinect_ros_driver)/launch/driver.launch">
    <arg name="depth_mode" value="$(arg depth_mode)"/>
    <arg name="color_resolution" value="$(arg color_resolution)"/>
    <arg name="fps" value="$(arg fps)"/>
    <arg name="point_cloud" value="$(arg point_cloud)"/>
    <arg name="rgb_point_cloud" value="$(arg rgb_point_cloud)"/>
  </include>

  <!-- ArUco marker tracking -->
  <node pkg="aruco_ros" type="single" name="aruco_single">
    <remap from="image" to="$(arg camera_image_topic)"/>
    <remap from="camera_info" to="$(arg camera_info_topic)"/>
    <param name="image_is_rectified" value="true"/>
    <param name="marker_size" value="$(arg marker_size)"/>
    <param name="marker_id" value="$(arg marker_id)"/>
    <param name="reference_frame" value="$(arg tracking_base_frame)"/>
    <param name="camera_frame" value="$(arg camera_frame)"/>
    <param name="marker_frame" value="$(arg marker_frame)"/>
    <param name="corner_refinement" value="$(arg corner_refinement)"/>
  </node>

  <!-- (Optional but often useful) Pose->TF publisher, same as in your calibration launch
       If you already have a TF from tracking_base_frame -> marker_frame, you can remove this.
  -->
  <node pkg="easy_handeye" type="pose_to_tf.py" name="aruco_pose_to_tf" output="screen">
    <param name="pose_topic" value="/aruco_single/pose"/>
    <param name="parent_frame" value="$(arg tracking_base_frame)"/>
    <param name="child_frame" value="$(arg marker_frame)"/>
  </node>

</launch>
